{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importa a biblioteca usada para trabalhar com vetores de matrizes\n",
    "%run normalization_utils.py\n",
    "\n",
    "X, Y, feature_names = build_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run normalization_utils.py\n",
    "\n",
    "X_1000, Y, feature_names_1000, freq_list_1000 = build_reduced_bow(1000,\n",
    "                                                                      'data/bow/reduced/best_words_1000.txt',\n",
    "                                                                      'data/bow/reduced/best_frequency_1000.txt',\n",
    "                                                                      'data/bow/reduced/reduced_bow_1000.npz',\n",
    "                                                                      False)\n",
    "\n",
    "X_5000, Y, feature_names_5000, freq_list_5000 = build_reduced_bow(5000,\n",
    "                                                                      'data/bow/reduced/best_words_5000.txt',\n",
    "                                                                      'data/bow/reduced/best_frequency_5000.txt',\n",
    "                                                                      'data/bow/reduced/reduced_bow_5000.npz',\n",
    "                                                                      False)\n",
    "\n",
    "X_10000, Y, feature_names_10000, freq_list_10000 = build_reduced_bow(10000,\n",
    "                                                                      'data/bow/reduced/best_words_10000.txt',\n",
    "                                                                      'data/bow/reduced/best_frequency_10000.txt',\n",
    "                                                                      'data/bow/reduced/reduced_bow_10000.npz',\n",
    "                                                                      False)\n",
    "\n",
    "X_b_1000, Y, feature_names_b_1000, freq_list_b_1000 = build_reduced_bow(1000,\n",
    "                                                                              'data/bow/reduced_binary/best_words_1000.txt',\n",
    "                                                                              'data/bow/reduced_binary/best_frequency_1000.txt',\n",
    "                                                                              'data/bow/reduced_binary/reduced_bow_1000.npz',\n",
    "                                                                              True)\n",
    "\n",
    "X_b_5000, Y, feature_names_b_5000, freq_list_b_5000 = build_reduced_bow(5000,\n",
    "                                                                              'data/bow/reduced_binary/best_words_5000.txt',\n",
    "                                                                              'data/bow/reduced_binary/best_frequency_5000.txt',\n",
    "                                                                              'data/bow/reduced_binary/reduced_bow_5000.npz',\n",
    "                                                                              True)\n",
    "\n",
    "X_b_10000, Y, feature_names_b_10000, freq_list_b_10000 = build_reduced_bow(10000,\n",
    "                                                                              'data/bow/reduced_binary/best_words_10000.txt',\n",
    "                                                                              'data/bow/reduced_binary/best_frequency_10000.txt',\n",
    "                                                                              'data/bow/reduced_binary/reduced_bow_10000.npz',\n",
    "                                                                              True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando metodo para converter uma string numa amostra para predição\n",
    "sentence = 'Tinha uma pedra no meio do caminho, no meio do caminho tinha uma pedra. Qual é o sentido da vida se a nossa existência é tão efemera.'\n",
    "\n",
    "a = sentence_to_features(sentence, feature_names_1000)\n",
    "\n",
    "print(a[a!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculando folds...')\n",
    "folds = stratified_kfolds(Y, 5)\n",
    "print('Folds calculados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[folds[0][0]]\n",
    "Ytrain = Y[folds[0][0]]\n",
    "\n",
    "Xtest = X[folds[0][1]]\n",
    "Ytest = Y[folds[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'common': X,\n",
    "    'reduced_1000': X_1000,\n",
    "    'reduced_5000': X_5000,\n",
    "    'reduced_10000': X_10000,\n",
    "    'reduced_binary_1000': X_b_1000,\n",
    "    'reduced_binary_5000': X_b_5000,\n",
    "    'reduced_binary_10000': X_b_10000\n",
    "}\n",
    "\n",
    "keys = list(datasets.keys())\n",
    "\n",
    "bestDatasets = {}\n",
    "\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/Kneighbors.py\n",
    "%run normalization_utils.py\n",
    "%run saveAcc.py\n",
    "\n",
    "bestAccuracy = 0\n",
    "bestK = -1\n",
    "bestDataset = ''\n",
    "\n",
    "for key in keys:\n",
    "    for k in range(1, 101, 2):\n",
    "        print('%s bow - %d/%d' %(key, k, 101), end='\\r', flush=True)\n",
    "        acc = 0\n",
    "        for i in range(5):\n",
    "            Ypred = testSamples(datasets[key][folds[i][0]], Y[folds[i][0]], datasets[key][folds[i][1]], k)\n",
    "            result = get_performance(Y[folds[i][1]], Ypred)\n",
    "            acc = acc + result['acuracia']\n",
    "        saveAcuracia(k, acc/5, 'Knn')\n",
    "        if bestAccuracy < acc/5:\n",
    "            bestAccuracy = acc/5\n",
    "            bestK = k\n",
    "            bestDataset = key\n",
    "\n",
    "bestDatasets['knn'] = bestDataset\n",
    "print('Best -> K: ', bestK, ' acc: ', bestAccuracy, 'dataset: ', bestDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/Kneighbors.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "YtrainPred = testSamples(datasets[bestDatasets['knn']][folds[0][0]], Y[folds[0][0]], datasets[bestDatasets['knn']][folds[0][0]], bestK)\n",
    "YtestPred = testSamples(datasets[bestDatasets['knn']][folds[0][0]], Y[folds[0][0]], datasets[bestDatasets['knn']][folds[0][1]], bestK)\n",
    "\n",
    "print('Acuracia do treino: ', get_performance(Y[folds[0][0]], YtrainPred)['acuracia'])\n",
    "print('Acuracia do teste: ', get_performance(Y[folds[0][1]], YtestPred)['acuracia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/logisticRegression.py\n",
    "%run normalization_utils.py\n",
    "%run saveAcc.py\n",
    "\n",
    "bestAcuracia = 0\n",
    "bestLambda = -1\n",
    "bestDataset = ''\n",
    "results = []\n",
    "\n",
    "for key in keys:\n",
    "    for i in range(0, 1001, 50):\n",
    "        print('%s bow - %d/%d' %(key, i, 1001), end='\\r', flush=True)\n",
    "        acc = 0\n",
    "        for j in range(5):\n",
    "            theta, Ypred = regression(datasets[key][folds[j][0]], Y[folds[j][0]], datasets[key][folds[j][1]], i)\n",
    "            result = get_performance(Y[folds[j][1]], Ypred)\n",
    "            acc = acc + result['acuracia']\n",
    "        saveAcuracia(i, acc/5,'logistic_regression')\n",
    "        if bestAcuracia < acc/5:\n",
    "            bestAcuracia = acc/5\n",
    "            bestLambda = i\n",
    "            bestDataset = key\n",
    "\n",
    "bestDatasets['logistic_regression'] = bestDataset\n",
    "print('Melhor Lambda: ', bestLambda, 'com acuracia:', bestAcuracia, 'dataset: ', bestDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/logisticRegression.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "theta, YtestPred = regression(datasets[bestDatasets['logistic_regression']][folds[0][0]], Y[folds[0][0]], datasets[bestDatasets['logistic_regression']][folds[0][1]], bestLambda)\n",
    "YtrainPred = predict(theta, datasets[bestDatasets['logistic_regression']][folds[0][0]])\n",
    "\n",
    "print('Acuracia do treino: ', get_performance(Y[folds[0][0]], YtrainPred)['acuracia'])\n",
    "print('Acuracia do teste: ', get_performance(Y[folds[0][1]], YtestPred)['acuracia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/naiveBayes.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "bestAcuracia = 0\n",
    "bestDataset = ''\n",
    "\n",
    "results = []\n",
    "\n",
    "for key in keys:\n",
    "    print('Utilizando %s bow' %key, flush=True)\n",
    "    acc = 0\n",
    "    for i in range(5):\n",
    "        Ypred = naiveBayes(datasets[key][folds[i][0]], Y[folds[i][0]],  datasets[key][folds[i][1]])\n",
    "        result = get_performance(Y[folds[i][1]], Ypred)\n",
    "        acc = acc + result['acuracia']\n",
    "    results.append(acc/5)\n",
    "    if bestAcuracia < acc/5:\n",
    "        bestAcuracia = acc/5\n",
    "        bestDataset = key\n",
    "        \n",
    "bestDatasets['naive_bayes'] = bestDataset\n",
    "print('Acuracia:', bestAcuracia, 'dataset: ', bestDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/naiveBayes.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "YtrainPred = naiveBayes(datasets[bestDatasets['naive_bayes']][folds[0][0]], Y[folds[0][0]], datasets[bestDatasets['naive_bayes']][folds[0][0]])\n",
    "YtestPred = naiveBayes(datasets[bestDatasets['naive_bayes']][folds[0][0]], Y[folds[0][0]], datasets[bestDatasets['naive_bayes']][folds[0][1]])\n",
    "\n",
    "print('Acuracia do treino: ', get_performance(Y[folds[0][0]], YtrainPred)['acuracia'])\n",
    "print('Acuracia do teste: ', get_performance(Y[folds[0][1]], YtestPred)['acuracia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/neuralNetworks.py\n",
    "%run normalization_utils.py\n",
    "%run saveAcc.py\n",
    "\n",
    "bestLambda = 0\n",
    "bestAcc = 0\n",
    "bestDataset = ''\n",
    "\n",
    "for key in keys:\n",
    "    vLambda = 0.001\n",
    "    for i in range(8):\n",
    "        print('%s bow - %d/%d' %(key, i, 7), end='\\r', flush=True)\n",
    "        acc = 0\n",
    "        for j in range(5):\n",
    "            Ypred, Theta1, Theta2 = neuralNetwork(datasets[key][folds[j][0]], Y[folds[j][0]], datasets[key][folds[j][1]], vLambda)\n",
    "            result = get_performance(Y[folds[j][1]], Ypred)\n",
    "            acc = acc + result['acuracia']\n",
    "        saveAcuracia(vLambda, acc/5, 'neuralNetworks')\n",
    "        if bestAcc < acc/5:\n",
    "            bestAcc = acc/5\n",
    "            bestLambda = vLambda\n",
    "            bestDataset = key\n",
    "        vLambda = vLambda * 10\n",
    "\n",
    "bestDatasets['neuralNetworks'] = bestDataset\n",
    "print('Lambda', bestLambda, 'Acuracia:', bestAcc, 'dataset: ', bestDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/neuralNetworks.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "YtestPred, Theta1, Theta2 = neuralNetwork(datasets[bestDatasets['neuralNetworks']][folds[0][0]], Y[folds[0][0]], datasets[bestDatasets['neuralNetworks']][folds[0][1]], bestLambda)\n",
    "YtrainPred = predict(Theta1, Theta2, datasets[bestDatasets['neuralNetworks']][folds[0][0]])\n",
    "\n",
    "print('Acuracia do treino: ', get_performance(Y[folds[0][0]], YtrainPred)['acuracia'])\n",
    "print('Acuracia do teste: ', get_performance(Y[folds[0][1]], YtestPred)['acuracia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/svmMethod.py\n",
    "%run normalization_utils.py\n",
    "%run saveAcc.py\n",
    "\n",
    "kernel = 0\n",
    "bestCost = 0\n",
    "bestAcc = 0\n",
    "bestDataset = ''\n",
    "\n",
    "for key in keys:\n",
    "    for cost in range(1, 101, 10):\n",
    "        print('%s bow - %d/%d' %(key, cost, 100), end='\\r', flush=True)\n",
    "        acc = 0\n",
    "        for i in range(5):\n",
    "            model, Ypred = svmUse(datasets[key][folds[i][0]], Y[folds[i][0]], datasets[key][folds[i][1]], Y[folds[i][1]], kernel, cost, 0)\n",
    "            acc += get_performance(Y[folds[i][1]], Ypred)['acuracia']\n",
    "        saveAcuracia(cost, acc/5, 'svm')\n",
    "        if bestAcc < acc/5:\n",
    "            bestCost = cost\n",
    "            bestAcc = acc/5\n",
    "            bestDataset = key\n",
    "            \n",
    "bestDatasets['svm'] = bestDataset\n",
    "print('cost:', bestCost, ' kernel:', kernel, 'accuracy:', bestAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/svmMethod.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "kernel = 0\n",
    "\n",
    "model = train(datasets[bestDatasets['svm']][folds[0][0]], Y[folds[0][0]], kernel, 51, 0)\n",
    "YtrainPred = predict(model, datasets[bestDatasets['svm']][folds[0][0]], Y[folds[0][0]])\n",
    "YtestPred = predict(model, datasets[bestDatasets['svm']][folds[0][1]], Y[folds[0][1]])\n",
    "\n",
    "print('Acuracia do treino: ', get_performance(Y[folds[0][0]], YtrainPred)['acuracia'])\n",
    "print('Acuracia do teste: ', get_performance(Y[folds[0][1]], YtestPred)['acuracia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/naiveBayes.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "Xtrain = datasets[bestDatasets['naive_bayes']][folds[0][0]]\n",
    "Ytrain = Y[folds[0][0]]\n",
    "\n",
    "Xtest = datasets[bestDatasets['naive_bayes']][folds[0][1]]\n",
    "Ytest = Y[folds[0][1]]\n",
    "\n",
    "learning_curve(Xtrain,\n",
    "               Ytrain,\n",
    "               Xtest,\n",
    "               Ytest,\n",
    "               train,\n",
    "               lambda X, result: [predict(X.getrow(i).toarray(),\n",
    "                                          result[2],\n",
    "                                          result[3],\n",
    "                                          result[0],\n",
    "                                          result[1])[0] for i in range(X.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/Kneighbors.py\n",
    "%run normalization_utils.py\n",
    "\n",
    "Xtrain = datasets[bestDatasets['knn']][folds[0][0]]\n",
    "Ytrain = Y[folds[0][0]]\n",
    "\n",
    "Xtest = datasets[bestDatasets['knn']][folds[0][1]]\n",
    "Ytest = Y[folds[0][1]]\n",
    "\n",
    "K = 1\n",
    "\n",
    "learning_curve(Xtrain,\n",
    "               Ytrain,\n",
    "               Xtest,\n",
    "               Ytest,\n",
    "               lambda X, Y: [X, Y],\n",
    "               lambda X, result: testSamples(result[0], result[1], X, K),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Methods/logisticRegression\n",
    "%run normalization_utils.py\n",
    "\n",
    "Xtrain = datasets['common'][folds[0][0]]\n",
    "Ytrain = Y[folds[0][0]]\n",
    "\n",
    "Xtest = datasets['common'][folds[0][1]]\n",
    "Ytest = Y[folds[0][1]]\n",
    "\n",
    "lambda_reg = 50\n",
    "\n",
    "learning_curve(Xtrain,\n",
    "               Ytrain,\n",
    "               Xtest,\n",
    "               Ytest,\n",
    "               lambda X, Y: train(X, Y, lambda_reg),\n",
    "               lambda X, result: predict(result, X),\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
